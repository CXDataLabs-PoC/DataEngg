{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc289a3-fa5e-42ae-a7f8-fbda413713b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "STORAGE_ACCOUNT = \"cxdlbbronze\"\n",
    "CONTAINER = \"landingzone\"\n",
    "Folder = \"BTC-USD\"\n",
    "\n",
    "lakehouse_path = f\"abfss://{CONTAINER}@{STORAGE_ACCOUNT}.dfs.core.windows.net/{Folder}\"\n",
    "checkpoint_path = lakehouse_path + \"_checkpoint/last_trade.json\"\n",
    "\n",
    "client_id = dbutils.secrets.get(scope=\"landingzone-secret\", key=\"client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"landingzone-secret\", key=\"client-secret\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"landingzone-secret\", key=\"tenant-id\")\n",
    "\n",
    "account_host = f\"{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{account_host}\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{account_host}\",\n",
    "               \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{account_host}\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{account_host}\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{account_host}\",\n",
    "               f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d93ea9d3-35ff-4f41-bb4c-19c5acc0d3b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.rm(\"abfss://landingzone@cxdlbbronze.dfs.core.windows.net/BTC-USD/\", recurse=True)\n",
    "dbutils.fs.rm(\"abfss://landingzone@cxdlbbronze.dfs.core.windows.net/BTC-USD_checkpoint/\", recurse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61659505-baa6-4307-8a2f-9453d18d1683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last processed trade_id = 876338437\n+---------------+----+----------+---------------------------+---------+\n|price          |side|size      |time                       |trade_id |\n+---------------+----+----------+---------------------------+---------+\n|115562.44000000|buy |0.00003289|2025-09-21T04:59:31.301780Z|876338619|\n|115562.45000000|sell|0.01601281|2025-09-21T04:59:31.186107Z|876338618|\n|115562.45000000|sell|0.00845062|2025-09-21T04:59:31.186107Z|876338617|\n|115562.44000000|buy |0.00009599|2025-09-21T04:59:30.982376Z|876338616|\n|115562.45000000|sell|0.00019695|2025-09-21T04:59:29.919754Z|876338615|\n+---------------+----+----------+---------------------------+---------+\nonly showing top 5 rows\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/1879/command-8125373042043878-3142938176:85: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  .withColumn(\"ingest_ts\", lit(datetime.utcnow()))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 182 new trades. Updated watermark = 876338619\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, LongType, TimestampType, DecimalType, StringType\n",
    "from pyspark.sql.functions import col, lit, max as spark_max, to_timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "api_url = \"https://api.exchange.coinbase.com/products/BTC-USD/trades\"\n",
    "\n",
    "\n",
    "STORAGE_ACCOUNT = \"cxdlbbronze\"\n",
    "CONTAINER = \"landingzone\"\n",
    "Folder = \"BTC-USD\"\n",
    "\n",
    "lakehouse_path = f\"abfss://{CONTAINER}@{STORAGE_ACCOUNT}.dfs.core.windows.net/{Folder}\"\n",
    "checkpoint_path = lakehouse_path + \"_checkpoint/last_trade.json\"\n",
    "\n",
    "client_id = dbutils.secrets.get(scope=\"landingzone-secret\", key=\"client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"landingzone-secret\", key=\"client-secret\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"landingzone-secret\", key=\"tenant-id\")\n",
    "\n",
    "account_host = f\"{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{account_host}\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{account_host}\",\n",
    "               \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{account_host}\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{account_host}\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{account_host}\",\n",
    "               f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Get last watermark (trade_id)\n",
    "# -------------------------\n",
    "def get_last_trade_id():\n",
    "    try:\n",
    "        df = spark.read.json(checkpoint_path)\n",
    "        return df.collect()[0][\"last_trade_id\"]\n",
    "    except Exception:\n",
    "        return 0   # start from 0 for first run\n",
    "\n",
    "last_trade_id = get_last_trade_id()\n",
    "print(f\"Last processed trade_id = {last_trade_id}\")\n",
    "\n",
    "# -------------------------\n",
    "# Define standardized schema\n",
    "# -------------------------\n",
    "trade_schema = StructType([\n",
    "    StructField(\"trade_id\", LongType(), False),\n",
    "    StructField(\"trade_time\", TimestampType(), False),\n",
    "    StructField(\"price\", DecimalType(18,2), False),\n",
    "    StructField(\"size\", DecimalType(18,8), False),\n",
    "    StructField(\"side\", StringType(), False),\n",
    "    StructField(\"ingest_ts\", TimestampType(), False)\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Fetch trades from Coinbase API\n",
    "# -------------------------\n",
    "response = requests.get(api_url, headers={\"Accept\": \"application/json\"})\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"API call failed: {response.text}\")\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "raw_df = spark.read.json(spark.sparkContext.parallelize([json.dumps(d) for d in data]))\n",
    "\n",
    "# Coinbase API returns fields: time, trade_id, price, size, side\n",
    "raw_df.show(5, truncate=False)\n",
    "\n",
    "# -------------------------\n",
    "# Transform + Standardize schema\n",
    "# -------------------------\n",
    "df = (raw_df\n",
    "    .withColumn(\"trade_id\", col(\"trade_id\").cast(LongType()))\n",
    "    .withColumn(\"trade_time\", to_timestamp(col(\"time\")))\n",
    "    .withColumn(\"price\", col(\"price\").cast(DecimalType(18,2)))\n",
    "    .withColumn(\"size\", col(\"size\").cast(DecimalType(18,8)))\n",
    "    .withColumn(\"ingest_ts\", lit(datetime.utcnow()))\n",
    "    .select(\"trade_id\", \"trade_time\", \"price\", \"size\", \"side\", \"ingest_ts\")\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Filter Incremental Records\n",
    "# -------------------------\n",
    "df_incremental = df.filter(col(\"trade_id\") > last_trade_id)\n",
    "\n",
    "if df_incremental.count() == 0:\n",
    "    print(\"No new trades to load.\")\n",
    "else:\n",
    "    # Add load timestamp for auditing\n",
    "    df_incremental = df_incremental.withColumn(\"ingest_ts\", lit(datetime.now().isoformat()))\n",
    "\n",
    "    # -------------------------\n",
    "    # Write to Azure Data Lakehouse (Delta format)\n",
    "    # -------------------------\n",
    "    df_incremental.write.format(\"delta\").mode(\"append\").save(lakehouse_path)\n",
    "\n",
    "    # -------------------------\n",
    "    # Update watermark\n",
    "    # -------------------------\n",
    "    new_trade_id = df_incremental.agg(spark_max(\"trade_id\")).collect()[0][0]\n",
    "    spark.createDataFrame([{\"last_trade_id\": new_trade_id}]).write.mode(\"append\").json(checkpoint_path)\n",
    "\n",
    "    print(f\"✅ Loaded {df_incremental.count()} new trades. Updated watermark = {new_trade_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9efa45e-a9f9-4afc-843a-97bd4d18c149",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"first_trade\":279,\"last_trade\":282},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758384115254}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_trades</th><th>first_trade</th><th>last_trade</th></tr></thead><tbody><tr><td>1182</td><td>2025-09-21T04:48:01.960238Z</td><td>2025-09-21T04:59:31.30178Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1182,
         "2025-09-21T04:48:01.960238Z",
         "2025-09-21T04:59:31.30178Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "total_trades",
            "nullable": false,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "first_trade",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "last_trade",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 7
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_trades",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "first_trade",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "last_trade",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS total_trades,\n",
    "       MIN(trade_time) AS first_trade,\n",
    "       MAX(trade_time) AS last_trade\n",
    "FROM hive_metastore.raw_bronze.btc_usd_trades;\n",
    " "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8125373042043880,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "LiveAPI-ADLS",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}